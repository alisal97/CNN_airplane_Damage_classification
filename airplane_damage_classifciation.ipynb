{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-07vyUTGaSSm",
        "outputId": "d2ca669c-96a5-4448-c70d-7f5958538ff4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Read the CSV files for train, validation, and test sets**\n",
        "*   Read the CSV files containing the class labels for the train, validation, and test sets.\n",
        "*   Define the class labels for the classification task.\n",
        "*   Retrieve the image file paths and labels from the CSV files for the train, validation, and test sets.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tZk9TfboycVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "# Step 1: Read the CSV files for train, validation, and test sets\n",
        "train_class_file = pd.read_csv('/content/gdrive/My Drive/TensorFlow/Data/classification/train/_classes.csv')\n",
        "val_class_file = pd.read_csv('/content/gdrive/My Drive/TensorFlow/Data/classification/valid/_classes.csv')\n",
        "test_class_file = pd.read_csv('/content/gdrive/My Drive/TensorFlow/Data/classification/test/_classes.csv')\n",
        "\n",
        "class_labels = ['Abrasione', 'Ammaccatura', 'Crepa']\n",
        "\n",
        "train_image_files = train_class_file['filename'].values\n",
        "train_labels = train_class_file[['Abrasione', 'Ammaccatura', 'Crepa']].values\n",
        "\n",
        "val_image_files = val_class_file['filename'].values\n",
        "val_labels = val_class_file[['Abrasione', 'Ammaccatura', 'Crepa']].values\n",
        "\n",
        "test_image_files = test_class_file['filename'].values\n",
        "test_labels = test_class_file[['Abrasione', 'Ammaccatura', 'Crepa']].values\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "324UBEy-L-CO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Preprocess the images**\n",
        "\n",
        "\n",
        "*  Define a function preprocess_image to preprocess the images.\n",
        "\n",
        "  *   Check if the image file exists.\n",
        "  *   Read the image using OpenCV.\n",
        "  *   Convert the image to grayscale.\n",
        "  *   Resize the image to a target size.\n",
        "  *   Normalize the pixel values.\n",
        "  *   Add a single channel dimension to the image.\n",
        "  *   Return the preprocessed image.\n",
        "*   Specify the image directory paths for the train, validation, and test sets.\n",
        "*   Load and preprocess the images for the train, validation, and test sets using the preprocess_image function.\n",
        "* Dataset augmentation\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tKrs4_SnzG9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(file_path, target_size):\n",
        "    if not os.path.isfile(file_path):\n",
        "        raise FileNotFoundError(f\"Image file not found: {file_path}\")\n",
        "\n",
        "    image = cv2.imread(file_path)\n",
        "    if image is None:\n",
        "        raise ValueError(f\"Invalid image file: {file_path}\")\n",
        "\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
        "    image = cv2.resize(image, target_size)\n",
        "    image = image.astype(np.float32) / 255.0  # Normalize pixel values\n",
        "    image = np.expand_dims(image, axis=-1)  # Add a single channel dimension\n",
        "    return image\n",
        "\n",
        "\n",
        "# Specify the image directory paths\n",
        "train_image_dir = '/content/gdrive/My Drive/TensorFlow/Data/classification/train/'\n",
        "val_image_dir = '/content/gdrive/My Drive/TensorFlow/Data/classification/valid/'\n",
        "test_image_dir = '/content/gdrive/My Drive/TensorFlow/Data/classification/test/'\n",
        "\n",
        "# Load and preprocess images for train set\n",
        "train_preprocessed_images = []\n",
        "for file_name in train_image_files:\n",
        "    file_path = os.path.join(train_image_dir, file_name)\n",
        "    try:\n",
        "        image = preprocess_image(file_path, (416, 416))\n",
        "        train_preprocessed_images.append(image)\n",
        "    except (FileNotFoundError, ValueError) as e:\n",
        "        print(f\"Error processing image {file_path}: {str(e)}\")\n",
        "\n",
        "train_preprocessed_images = np.array(train_preprocessed_images)\n",
        "\n",
        "# Load and preprocess images for validation set\n",
        "val_preprocessed_images = []\n",
        "for file_name in val_image_files:\n",
        "    file_path = os.path.join(val_image_dir, file_name)\n",
        "    try:\n",
        "        image = preprocess_image(file_path, (416, 416))\n",
        "        val_preprocessed_images.append(image)\n",
        "    except (FileNotFoundError, ValueError) as e:\n",
        "        print(f\"Error processing image {file_path}: {str(e)}\")\n",
        "\n",
        "val_preprocessed_images = np.array(val_preprocessed_images)\n",
        "\n",
        "# Load and preprocess images for test set\n",
        "test_preprocessed_images = []\n",
        "for file_name in test_image_files:\n",
        "    file_path = os.path.join(test_image_dir, file_name)\n",
        "    try:\n",
        "        image = preprocess_image(file_path, (416, 416))\n",
        "        test_preprocessed_images.append(image)\n",
        "    except (FileNotFoundError, ValueError) as e:\n",
        "        print(f\"Error processing image {file_path}: {str(e)}\")\n",
        "\n",
        "test_preprocessed_images = np.array(test_preprocessed_images)\n"
      ],
      "metadata": {
        "id": "vMOAnkOwyuvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imgaug import augmenters as iaa\n",
        "\n",
        "def augment_image(image):\n",
        "    # Define the image augmentations\n",
        "    seq = iaa.Sequential([\n",
        "        iaa.Fliplr(0.5),  # Horizontal flip with 50% probability\n",
        "        iaa.Affine(\n",
        "            rotate=(-20, 20),  # Rotate by -20 to 20 degrees\n",
        "            scale=(0.8, 1.2),  # Scale by 0.8 to 1.2\n",
        "            shear=(-0.2, 0.2),  # Shear by -0.2 to 0.2\n",
        "        ),\n",
        "    ])\n",
        "\n",
        "    # Apply the image augmentations to the image\n",
        "    augmented_image = seq.augment_image(image)\n",
        "\n",
        "    return augmented_image\n",
        "\n",
        "\n",
        "# Augment the train images\n",
        "augmented_train_images = []\n",
        "for image in train_preprocessed_images:\n",
        "    augmented_image = augment_image(image)\n",
        "    augmented_train_images.append(augmented_image)\n",
        "\n",
        "train_preprocessed_images = np.array(augmented_train_images)\n"
      ],
      "metadata": {
        "id": "brxutK_nQdJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Encode the labels**\n",
        "\n",
        "\n",
        "*   Use LabelBinarizer from scikit-learn to encode the class labels into binary vectors.\n",
        "\n",
        "*   Encode the labels for the train, validation, and test sets.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JNf3vAdWz-NO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lb = LabelBinarizer()\n",
        "\n",
        "encoded_train_labels = lb.fit_transform(train_labels)\n",
        "encoded_val_labels = lb.transform(val_labels)\n",
        "encoded_test_labels = lb.transform(test_labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "VTjMPVhmyu0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making sure our dataset has been preproccessed correctly.\n",
        "\n"
      ],
      "metadata": {
        "id": "zcXUN7kYedRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the encoded labels for train, validation, and test sets\n",
        "print(\"Encoded Train Labels:\")\n",
        "print(encoded_train_labels)\n",
        "print(\"Encoded Validation Labels:\")\n",
        "print(encoded_val_labels)\n",
        "print(\"Encoded Test Labels:\")\n",
        "print(encoded_test_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLdqYYDpy9SD",
        "outputId": "dec34ee0-532d-4d49-ca79-ad8e9ea1882e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded Train Labels:\n",
            "[[0 0 1]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [1 0 1]\n",
            " [0 1 1]\n",
            " [1 0 1]\n",
            " [0 0 1]\n",
            " [1 0 1]\n",
            " [0 0 1]\n",
            " [1 0 1]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [1 0 1]\n",
            " [0 0 1]\n",
            " [1 0 1]\n",
            " [0 0 1]\n",
            " [0 1 1]\n",
            " [0 0 1]\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [0 0 1]\n",
            " [1 0 1]]\n",
            "Encoded Validation Labels:\n",
            "[[1 0 0]\n",
            " [1 0 0]\n",
            " [0 1 1]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " [0 0 1]]\n",
            "Encoded Test Labels:\n",
            "[[0 1 0]\n",
            " [0 1 0]\n",
            " [0 0 1]\n",
            " [1 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We print the image name and the corresponding encoded labels**"
      ],
      "metadata": {
        "id": "Jl5T8lYveJoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for filename, encoded_label in zip(train_preprocessed_images, encoded_train_labels):\n",
        "    print(f\"Image: {filename}, Encoded Label: {encoded_label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJhgCOvJLEVN",
        "outputId": "438865af-7548-4ca4-f1e8-d9c9dd399049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: [[[0.66899514]\n",
            "  [0.6672871 ]\n",
            "  [0.66506594]\n",
            "  ...\n",
            "  [0.28104323]\n",
            "  [0.28936505]\n",
            "  [0.2952359 ]]\n",
            "\n",
            " [[0.6683326 ]\n",
            "  [0.6668582 ]\n",
            "  [0.6671952 ]\n",
            "  ...\n",
            "  [0.26953125]\n",
            "  [0.28278953]\n",
            "  [0.2920956 ]]\n",
            "\n",
            " [[0.670324  ]\n",
            "  [0.6675016 ]\n",
            "  [0.67001384]\n",
            "  ...\n",
            "  [0.26678923]\n",
            "  [0.28280485]\n",
            "  [0.2916667 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.6556449 ]\n",
            "  [0.6474265 ]\n",
            "  [0.64395684]\n",
            "  ...\n",
            "  [0.35179228]\n",
            "  [0.3466146 ]\n",
            "  [0.349303  ]]\n",
            "\n",
            " [[0.65621936]\n",
            "  [0.65159315]\n",
            "  [0.6473575 ]\n",
            "  ...\n",
            "  [0.36577052]\n",
            "  [0.35588238]\n",
            "  [0.3540441 ]]\n",
            "\n",
            " [[0.6593597 ]\n",
            "  [0.6613971 ]\n",
            "  [0.654722  ]\n",
            "  ...\n",
            "  [0.36456805]\n",
            "  [0.36202514]\n",
            "  [0.3629098 ]]], Encoded Label: [0 0 1]\n",
            "Image: [[[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]], Encoded Label: [0 1 0]\n",
            "Image: [[[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]], Encoded Label: [0 0 1]\n",
            "Image: [[[0.6246783 ]\n",
            "  [0.86176467]\n",
            "  [0.85294116]\n",
            "  ...\n",
            "  [0.27713698]\n",
            "  [0.23676473]\n",
            "  [0.19474955]]\n",
            "\n",
            " [[0.7617647 ]\n",
            "  [0.8665365 ]\n",
            "  [0.8617188 ]\n",
            "  ...\n",
            "  [0.27397364]\n",
            "  [0.27058825]\n",
            "  [0.27169117]]\n",
            "\n",
            " [[0.85964304]\n",
            "  [0.86337316]\n",
            "  [0.8661152 ]\n",
            "  ...\n",
            "  [0.26973042]\n",
            "  [0.26969212]\n",
            "  [0.2729473 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.5997549 ]\n",
            "  [0.603102  ]\n",
            "  [0.6066176 ]\n",
            "  ...\n",
            "  [0.18367036]\n",
            "  [0.14636949]\n",
            "  [0.11630668]]\n",
            "\n",
            " [[0.59766394]\n",
            "  [0.5988971 ]\n",
            "  [0.6009038 ]\n",
            "  ...\n",
            "  [0.12480086]\n",
            "  [0.12535998]\n",
            "  [0.08246017]]\n",
            "\n",
            " [[0.4284314 ]\n",
            "  [0.52156866]\n",
            "  [0.59626997]\n",
            "  ...\n",
            "  [0.09120711]\n",
            "  [0.09367341]\n",
            "  [0.05328967]]], Encoded Label: [0 0 1]\n",
            "Image: [[[0.60392165]\n",
            "  [0.60649514]\n",
            "  [0.6091452 ]\n",
            "  ...\n",
            "  [0.3870098 ]\n",
            "  [0.38627452]\n",
            "  [0.38661152]]\n",
            "\n",
            " [[0.6039216 ]\n",
            "  [0.6062499 ]\n",
            "  [0.6112324 ]\n",
            "  ...\n",
            "  [0.38431373]\n",
            "  [0.38431373]\n",
            "  [0.38938802]]\n",
            "\n",
            " [[0.6039216 ]\n",
            "  [0.6060049 ]\n",
            "  [0.6093137 ]\n",
            "  ...\n",
            "  [0.38578433]\n",
            "  [0.38615197]\n",
            "  [0.39178923]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.8294041 ]\n",
            "  [0.8326785 ]\n",
            "  [0.8303921 ]\n",
            "  ...\n",
            "  [0.11617647]\n",
            "  [0.1192402 ]\n",
            "  [0.12124694]]\n",
            "\n",
            " [[0.82387024]\n",
            "  [0.8194853 ]\n",
            "  [0.81825984]\n",
            "  ...\n",
            "  [0.1125    ]\n",
            "  [0.11568627]\n",
            "  [0.11871936]]\n",
            "\n",
            " [[0.8135876 ]\n",
            "  [0.8039216 ]\n",
            "  [0.802451  ]\n",
            "  ...\n",
            "  [0.11037837]\n",
            "  [0.11095665]\n",
            "  [0.11052389]]], Encoded Label: [1 0 0]\n",
            "Image: [[[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]], Encoded Label: [0 0 1]\n",
            "Image: [[[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]], Encoded Label: [1 0 0]\n",
            "Image: [[[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]], Encoded Label: [1 0 1]\n",
            "Image: [[[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]], Encoded Label: [0 1 1]\n",
            "Image: [[[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]], Encoded Label: [1 0 1]\n",
            "Image: [[[0.44483763]\n",
            "  [0.44688267]\n",
            "  [0.44705883]\n",
            "  ...\n",
            "  [0.29828432]\n",
            "  [0.2975605 ]\n",
            "  [0.2927696 ]]\n",
            "\n",
            " [[0.44606698]\n",
            "  [0.44607842]\n",
            "  [0.4465686 ]\n",
            "  ...\n",
            "  [0.29791665]\n",
            "  [0.29460785]\n",
            "  [0.2887255 ]]\n",
            "\n",
            " [[0.4420343 ]\n",
            "  [0.43946078]\n",
            "  [0.439951  ]\n",
            "  ...\n",
            "  [0.29767156]\n",
            "  [0.29436275]\n",
            "  [0.2879902 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.608701  ]\n",
            "  [0.6120098 ]\n",
            "  [0.6153186 ]\n",
            "  ...\n",
            "  [0.21960784]\n",
            "  [0.21960784]\n",
            "  [0.22267157]]\n",
            "\n",
            " [[0.60876995]\n",
            "  [0.6122549 ]\n",
            "  [0.61556375]\n",
            "  ...\n",
            "  [0.21960784]\n",
            "  [0.21960784]\n",
            "  [0.22291666]]\n",
            "\n",
            " [[0.60709256]\n",
            "  [0.61262256]\n",
            "  [0.6159314 ]\n",
            "  ...\n",
            "  [0.21654412]\n",
            "  [0.21703431]\n",
            "  [0.22071078]]], Encoded Label: [0 0 1]\n",
            "Image: [[[0.41960785]\n",
            "  [0.41960782]\n",
            "  [0.41960785]\n",
            "  ...\n",
            "  [0.4083333 ]\n",
            "  [0.476348  ]\n",
            "  [0.5103631 ]]\n",
            "\n",
            " [[0.41960782]\n",
            "  [0.41960785]\n",
            "  [0.41960788]\n",
            "  ...\n",
            "  [0.42504597]\n",
            "  [0.4897442 ]\n",
            "  [0.53406864]]\n",
            "\n",
            " [[0.4254902 ]\n",
            "  [0.41996017]\n",
            "  [0.4150582 ]\n",
            "  ...\n",
            "  [0.45400584]\n",
            "  [0.5078891 ]\n",
            "  [0.55704665]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.41280636]\n",
            "  [0.4278416 ]\n",
            "  [0.41680455]\n",
            "  ...\n",
            "  [0.30595896]\n",
            "  [0.37671572]\n",
            "  [0.3995098 ]]\n",
            "\n",
            " [[0.43241423]\n",
            "  [0.4532935 ]\n",
            "  [0.44312194]\n",
            "  ...\n",
            "  [0.27344516]\n",
            "  [0.29688266]\n",
            "  [0.27818626]]\n",
            "\n",
            " [[0.44904643]\n",
            "  [0.47579655]\n",
            "  [0.47156864]\n",
            "  ...\n",
            "  [0.22833946]\n",
            "  [0.24319854]\n",
            "  [0.24399127]]], Encoded Label: [1 0 1]\n",
            "Image: [[[0.32156864]\n",
            "  [0.32156864]\n",
            "  [0.3216452 ]\n",
            "  ...\n",
            "  [0.85245097]\n",
            "  [0.8507353 ]\n",
            "  [0.8490503 ]]\n",
            "\n",
            " [[0.32414216]\n",
            "  [0.32475492]\n",
            "  [0.32275584]\n",
            "  ...\n",
            "  [0.8471929 ]\n",
            "  [0.84411764]\n",
            "  [0.84363127]]\n",
            "\n",
            " [[0.3257353 ]\n",
            "  [0.32549024]\n",
            "  [0.3250996 ]\n",
            "  ...\n",
            "  [0.8503217 ]\n",
            "  [0.84600186]\n",
            "  [0.8522365 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.13734682]\n",
            "  [0.09915748]\n",
            "  [0.23584561]\n",
            "  ...\n",
            "  [0.6282093 ]\n",
            "  [0.6286765 ]\n",
            "  [0.6276961 ]]\n",
            "\n",
            " [[0.13357845]\n",
            "  [0.11403187]\n",
            "  [0.17019762]\n",
            "  ...\n",
            "  [0.62344515]\n",
            "  [0.62352943]\n",
            "  [0.62352943]]\n",
            "\n",
            " [[0.13261336]\n",
            "  [0.13265166]\n",
            "  [0.13480394]\n",
            "  ...\n",
            "  [0.62063426]\n",
            "  [0.62352943]\n",
            "  [0.6241269 ]]], Encoded Label: [0 0 1]\n",
            "Image: [[[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]], Encoded Label: [1 0 1]\n",
            "Image: [[[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]], Encoded Label: [0 0 1]\n",
            "Image: [[[0.37238434]\n",
            "  [0.37643996]\n",
            "  [0.38039216]\n",
            "  ...\n",
            "  [0.5939492 ]\n",
            "  [0.5410233 ]\n",
            "  [0.5238703 ]]\n",
            "\n",
            " [[0.37452513]\n",
            "  [0.3745098 ]\n",
            "  [0.37556678]\n",
            "  ...\n",
            "  [0.6226065 ]\n",
            "  [0.5867035 ]\n",
            "  [0.59791666]]\n",
            "\n",
            " [[0.37503448]\n",
            "  [0.36796492]\n",
            "  [0.36574754]\n",
            "  ...\n",
            "  [0.62662375]\n",
            "  [0.61639094]\n",
            "  [0.64635426]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.45710784]\n",
            "  [0.45424324]\n",
            "  [0.45294118]\n",
            "  ...\n",
            "  [0.98823524]\n",
            "  [0.98823535]\n",
            "  [0.98823535]]\n",
            "\n",
            " [[0.45343137]\n",
            "  [0.45036766]\n",
            "  [0.44785157]\n",
            "  ...\n",
            "  [0.9904412 ]\n",
            "  [0.9901961 ]\n",
            "  [0.9899509 ]]\n",
            "\n",
            " [[0.45208335]\n",
            "  [0.44760266]\n",
            "  [0.44362745]\n",
            "  ...\n",
            "  [0.99215686]\n",
            "  [0.99215686]\n",
            "  [0.9921568 ]]], Encoded Label: [0 0 1]\n",
            "Image: [[[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]], Encoded Label: [0 0 1]\n",
            "Image: [[[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]], Encoded Label: [0 1 0]\n",
            "Image: [[[0.53333336]\n",
            "  [0.5319853 ]\n",
            "  [0.53100497]\n",
            "  ...\n",
            "  [0.47450978]\n",
            "  [0.47561276]\n",
            "  [0.47801012]]\n",
            "\n",
            " [[0.53333336]\n",
            "  [0.53333336]\n",
            "  [0.5333333 ]\n",
            "  ...\n",
            "  [0.48737746]\n",
            "  [0.48484987]\n",
            "  [0.48186275]]\n",
            "\n",
            " [[0.53333336]\n",
            "  [0.5333334 ]\n",
            "  [0.53333336]\n",
            "  ...\n",
            "  [0.48958334]\n",
            "  [0.48922718]\n",
            "  [0.48615193]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.40602788]\n",
            "  [0.3492647 ]\n",
            "  [0.2659314 ]\n",
            "  ...\n",
            "  [0.8981005 ]\n",
            "  [0.81531864]\n",
            "  [0.775     ]]\n",
            "\n",
            " [[0.38750002]\n",
            "  [0.3257813 ]\n",
            "  [0.2529412 ]\n",
            "  ...\n",
            "  [0.8913833 ]\n",
            "  [0.8116268 ]\n",
            "  [0.7159008 ]]\n",
            "\n",
            " [[0.3720282 ]\n",
            "  [0.32653952]\n",
            "  [0.25134805]\n",
            "  ...\n",
            "  [0.8995788 ]\n",
            "  [0.84068626]\n",
            "  [0.74617803]]], Encoded Label: [1 0 1]\n",
            "Image: [[[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]], Encoded Label: [0 0 1]\n",
            "Image: [[[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]], Encoded Label: [1 0 1]\n",
            "Image: [[[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]], Encoded Label: [0 0 1]\n",
            "Image: [[[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]], Encoded Label: [0 1 1]\n",
            "Image: [[[0.6627451 ]\n",
            "  [0.6627451 ]\n",
            "  [0.6627451 ]\n",
            "  ...\n",
            "  [0.7042892 ]\n",
            "  [0.70772064]\n",
            "  [0.70980394]]\n",
            "\n",
            " [[0.6627451 ]\n",
            "  [0.6627451 ]\n",
            "  [0.6627451 ]\n",
            "  ...\n",
            "  [0.70453435]\n",
            "  [0.70653343]\n",
            "  [0.7084942 ]]\n",
            "\n",
            " [[0.661152  ]\n",
            "  [0.6613971 ]\n",
            "  [0.6616422 ]\n",
            "  ...\n",
            "  [0.70301783]\n",
            "  [0.7050552 ]\n",
            "  [0.7078432 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.06568628]\n",
            "  [0.06749388]\n",
            "  [0.06443015]\n",
            "  ...\n",
            "  [0.267356  ]\n",
            "  [0.26697305]\n",
            "  [0.26812962]]\n",
            "\n",
            " [[0.06736366]\n",
            "  [0.06609222]\n",
            "  [0.06231618]\n",
            "  ...\n",
            "  [0.24675246]\n",
            "  [0.2513557 ]\n",
            "  [0.25231314]]\n",
            "\n",
            " [[0.06896447]\n",
            "  [0.06412761]\n",
            "  [0.06103707]\n",
            "  ...\n",
            "  [0.19803922]\n",
            "  [0.20273438]\n",
            "  [0.1989277 ]]], Encoded Label: [0 0 1]\n",
            "Image: [[[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]], Encoded Label: [1 0 0]\n",
            "Image: [[[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]], Encoded Label: [1 0 0]\n",
            "Image: [[[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]\n",
            "\n",
            " [[0.]\n",
            "  [0.]\n",
            "  [0.]\n",
            "  ...\n",
            "  [0.]\n",
            "  [0.]\n",
            "  [0.]]], Encoded Label: [0 0 1]\n",
            "Image: [[[0.35756743]\n",
            "  [0.35548407]\n",
            "  [0.35991114]\n",
            "  ...\n",
            "  [0.58406866]\n",
            "  [0.5845282 ]\n",
            "  [0.58431375]]\n",
            "\n",
            " [[0.3564032 ]\n",
            "  [0.35196078]\n",
            "  [0.3555147 ]\n",
            "  ...\n",
            "  [0.58431375]\n",
            "  [0.58480394]\n",
            "  [0.5852942 ]]\n",
            "\n",
            " [[0.35588235]\n",
            "  [0.3509804 ]\n",
            "  [0.35251227]\n",
            "  ...\n",
            "  [0.5941177 ]\n",
            "  [0.5946691 ]\n",
            "  [0.59188116]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.62496936]\n",
            "  [0.6082721 ]\n",
            "  [0.60312504]\n",
            "  ...\n",
            "  [0.3132353 ]\n",
            "  [0.31458336]\n",
            "  [0.3259804 ]]\n",
            "\n",
            " [[0.62861526]\n",
            "  [0.6136489 ]\n",
            "  [0.6120098 ]\n",
            "  ...\n",
            "  [0.31776962]\n",
            "  [0.31740198]\n",
            "  [0.32772672]]\n",
            "\n",
            " [[0.62564343]\n",
            "  [0.62585783]\n",
            "  [0.6237745 ]\n",
            "  ...\n",
            "  [0.3208027 ]\n",
            "  [0.3208793 ]\n",
            "  [0.32916668]]], Encoded Label: [1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Step 4: Commencing the training!**\n",
        "\n",
        "My idea is to do a comparison between a pretrained VGG16, LeNet-5 model architecture and a custom CNN architectured that I configuered.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VBsLIntccZyl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VGG16 Model Training**\n",
        "\n",
        "*   Convert the preprocessed train images to RGB format for compatibility with the VGG16 model.\n",
        "*   Load the pre-trained VGG16 model from TensorFlow's keras.applications module.\n",
        "*   Freeze the pre-trained layers of the VGG16 model.\n",
        "*   Add custom classification layers on top of the VGG16 model.\n",
        "*   Compile the model with the Adam optimizer and categorical cross-entropy loss.\n",
        "*   Train the model using the preprocessed train images and encoded train labels.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UlSPY-zqcwQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "#Converting the images to rgb for the vgg16 model\n",
        "train_preprocessed_images_rgb = np.repeat(train_preprocessed_images, 3, axis=-1)\n",
        "\n",
        "\n",
        "# Load the pre-trained VGG16 model\n",
        "vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(416, 416, 3))\n",
        "\n",
        "# Freeze the pre-trained layers\n",
        "for layer in vgg16.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom classification layers\n",
        "modelVGG = tf.keras.Sequential()\n",
        "modelVGG.add(vgg16)\n",
        "modelVGG.add(layers.Flatten())\n",
        "modelVGG.add(layers.Dense(256, activation='relu'))\n",
        "modelVGG.add(layers.Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "modelVGG.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "modelVGG.fit(train_preprocessed_images_rgb, encoded_train_labels, epochs=num_epochs, batch_size=batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lnd3Dn8h6G5a",
        "outputId": "09690708-4559-4154-b549-aea51d3eedde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 42s 42s/step - loss: 1.5479 - accuracy: 0.3214\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 43s 43s/step - loss: 16.4875 - accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 38s 38s/step - loss: 48.0560 - accuracy: 0.3929\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 38s 38s/step - loss: 22.5773 - accuracy: 0.8571\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 38s 38s/step - loss: 30.9330 - accuracy: 0.4643\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 38s 38s/step - loss: 36.1930 - accuracy: 0.4643\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 38s 38s/step - loss: 32.9467 - accuracy: 0.5357\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 38s 38s/step - loss: 27.5466 - accuracy: 0.6071\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 38s 38s/step - loss: 24.2673 - accuracy: 0.7500\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 38s 38s/step - loss: 26.5624 - accuracy: 0.8571\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9feaa65f60>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LeNet-5 Model Training**\n",
        "*   Define the LeNet-5 model architecture using Conv2D, MaxPooling2D, Flatten, and Dense layers.\n",
        "*   Compile the model with the Adam optimizer and categorical cross-entropy loss.\n",
        "*   Train the model using the preprocessed train images and encoded train labels.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8x_xkpm40yyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# LeNet-5 model architecture\n",
        "model_LeNet = tf.keras.Sequential()\n",
        "model_LeNet.add(layers.Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(416, 416, 1)))\n",
        "model_LeNet.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model_LeNet.add(layers.Conv2D(16, kernel_size=(5, 5), activation='relu'))\n",
        "model_LeNet.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model_LeNet.add(layers.Flatten())\n",
        "model_LeNet.add(layers.Dense(120, activation='relu'))\n",
        "model_LeNet.add(layers.Dense(84, activation='relu'))\n",
        "model_LeNet.add(layers.Dense(3, activation='softmax'))  # Modify the number of classes here\n",
        "\n",
        "# Compile the model\n",
        "model_LeNet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "model_LeNet.fit(train_preprocessed_images, encoded_train_labels, epochs=num_epochs, batch_size=batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "th9v_per_sal",
        "outputId": "0da1ac7c-da3a-4fc5-a6fe-257494bfb599"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.5351 - accuracy: 0.1429\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 2s 2s/step - loss: 16.7843 - accuracy: 0.4643\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 19.7014 - accuracy: 0.3929\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 6.5681 - accuracy: 0.4643\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 2s 2s/step - loss: 8.2976 - accuracy: 0.4643\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 2s 2s/step - loss: 10.9003 - accuracy: 0.3929\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 2s 2s/step - loss: 16.1135 - accuracy: 0.4643\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 4s 4s/step - loss: 21.4681 - accuracy: 0.4643\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 3s 3s/step - loss: 18.9440 - accuracy: 0.4643\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 2s 2s/step - loss: 27.7405 - accuracy: 0.3929\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9fd4400310>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom CNN Architecture Model Training**\n",
        "\n",
        "*   Define a custom model architecture using Conv2D, MaxPooling2D, Flatten, and Dense layers.\n",
        "*   Compile the model with the Adam optimizer and binary cross-entropy loss.\n",
        "*   Train the model using the preprocessed train images and encoded train labels.\n",
        "\n"
      ],
      "metadata": {
        "id": "a7HUMbBw1TsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_height = 416\n",
        "image_width = 416\n",
        "num_labels = 3\n",
        "channels = 1\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_height, image_width, channels)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(num_labels, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "batch_size = 32\n",
        "num_epochs = 10\n",
        "\n",
        "\n",
        "model.fit(train_preprocessed_images, encoded_train_labels, epochs=num_epochs, batch_size=batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldyDAjmVlNOa",
        "outputId": "900cb42b-2a39-45c2-f557-0106f111cb77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.7111 - accuracy: 0.1786\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 6s 6s/step - loss: 1.6297 - accuracy: 0.4643\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 7s 7s/step - loss: 1.1158 - accuracy: 0.5357\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.4773 - accuracy: 0.8571\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 10s 10s/step - loss: 0.4928 - accuracy: 0.4643\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3796 - accuracy: 0.6071\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 7s 7s/step - loss: 0.3717 - accuracy: 0.7500\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3224 - accuracy: 0.5357\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.2315 - accuracy: 0.6429\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.2051 - accuracy: 0.9286\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9fe882f010>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 5: Model Evaluation and Metrics**\n",
        "*   Evaluate all three models on the preprocessed validation images and encoded validation labels.\n",
        "*   Make predictions on the preprocessed test images using the trained models.\n",
        "*   Decode the model's output to obtain predicted labels.\n",
        "*   Calculate accuracy, precision, recall, and F1-score for each class.\n",
        "*   Print the classification report containing the evaluation metrics.\n"
      ],
      "metadata": {
        "id": "BccBpNO1bOjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "afrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "val_preproccessed_images_rgb = np.repeat(val_preprocessed_images, 3, axis=-1)\n",
        "# Evaluate the model\n",
        "val_loss_VGG, val_accuracy_VGG = modelVGG.evaluate(val_preproccessed_images_rgb, encoded_val_labels)\n",
        "print(\"Validation Loss:\", val_loss_VGG)\n",
        "print(\"Validation Accuracy:\", val_accuracy_VGG)\n",
        "\n",
        "# Make predictions on test data\n",
        "test_predictions = model.predict(test_preprocessed_images)\n",
        "# Decode the model's output to obtain predicted labels\n",
        "predicted_labels = lb.inverse_transform(test_predictions)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Convert encoded_test_labels to multiclass format\n",
        "test_labels = np.argmax(encoded_test_labels, axis=1)\n",
        "\n",
        "# Convert test_predictions to multiclass format\n",
        "predicted_classes = np.argmax(test_predictions, axis=1)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_VGG = accuracy_score(test_labels, predicted_classes)\n",
        "print(\"Accuracy:\", accuracy_VGG)\n",
        "\n",
        "\n",
        "# Calculate precision, recall, and F1-score for each class\n",
        "precision_VGG = precision_score(test_labels, predicted_classes, average=None, zero_division=1)\n",
        "recall_VGG = recall_score(test_labels, predicted_classes, average=None)\n",
        "f1_VGG = f1_score(test_labels, predicted_classes, average=None)\n",
        "\n",
        "# Print classification report\n",
        "for i, class_label in enumerate(class_labels):\n",
        "    print(\"Class:\", class_label)\n",
        "    print(\"Precision:\", precision_VGG[i])\n",
        "    print(\"Recall:\", recall_VGG[i])\n",
        "    print(\"F1-score:\", f1_VGG[i])\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qRYqQLgbE1c",
        "outputId": "773e6f9a-ed52-4ab5-8370-a642e1619fae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 11s 11s/step - loss: 49.0777 - accuracy: 0.5000\n",
            "Validation Loss: 49.077659606933594\n",
            "Validation Accuracy: 0.5\n",
            "1/1 [==============================] - 0s 382ms/step\n",
            "Accuracy: 0.5\n",
            "Class: Abrasione\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "\n",
            "Class: Ammaccatura\n",
            "Precision: 1.0\n",
            "Recall: 0.0\n",
            "F1-score: 0.0\n",
            "\n",
            "Class: Crepa\n",
            "Precision: 0.3333333333333333\n",
            "Recall: 1.0\n",
            "F1-score: 0.5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LeNet_5 Model Evaluation**\n"
      ],
      "metadata": {
        "id": "qJ6irJc6bUzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Evaluate the model\n",
        "val_loss_LeNet, val_accuracy_LeNet = model_LeNet.evaluate(val_preprocessed_images, encoded_val_labels)\n",
        "print(\"Validation Loss:\", val_loss_LeNet)\n",
        "print(\"Validation Accuracy:\", val_accuracy_LeNet)\n",
        "\n",
        "# Make predictions on test data\n",
        "test_predictions = model.predict(test_preprocessed_images)\n",
        "# Decode the model's output to obtain predicted labels\n",
        "predicted_labels = lb.inverse_transform(test_predictions)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Convert encoded_test_labels to multiclass format\n",
        "test_labels = np.argmax(encoded_test_labels, axis=1)\n",
        "\n",
        "# Convert test_predictions to multiclass format\n",
        "predicted_classes = np.argmax(test_predictions, axis=1)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_LeNet = accuracy_score(test_labels, predicted_classes)\n",
        "print(\"Accuracy:\", accuracy_LeNet)\n",
        "\n",
        "# Calculate precision, recall, and F1-score for each class\n",
        "precision_LeNet= precision_score(test_labels, predicted_classes, average=None, zero_division=1)\n",
        "recall_LeNet = recall_score(test_labels, predicted_classes, average=None)\n",
        "f1_LeNet = f1_score(test_labels, predicted_classes, average=None)\n",
        "\n",
        "# Print classification report\n",
        "for i, class_label in enumerate(class_labels):\n",
        "    print(\"Class:\", class_label)\n",
        "    print(\"Precision:\", precision_LeNet[i])\n",
        "    print(\"Recall:\", recall_LeNet[i])\n",
        "    print(\"F1-score:\", f1_LeNet[i])\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXUAkfmwa53s",
        "outputId": "7993ff6c-e8db-42bc-ebd0-99e979099544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 334ms/step - loss: 38.6784 - accuracy: 0.5000\n",
            "Validation Loss: 38.67838668823242\n",
            "Validation Accuracy: 0.5\n",
            "1/1 [==============================] - 0s 355ms/step\n",
            "Accuracy: 0.5\n",
            "Class: Abrasione\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "\n",
            "Class: Ammaccatura\n",
            "Precision: 1.0\n",
            "Recall: 0.0\n",
            "F1-score: 0.0\n",
            "\n",
            "Class: Crepa\n",
            "Precision: 0.3333333333333333\n",
            "Recall: 1.0\n",
            "F1-score: 0.5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom CNN Architecture Evaluation**\n"
      ],
      "metadata": {
        "id": "wBUHo8UBb_6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Evaluate the model\n",
        "val_loss, val_accuracy = model.evaluate(val_preprocessed_images, encoded_val_labels)\n",
        "print(\"Validation Loss:\", val_loss)\n",
        "print(\"Validation Accuracy:\", val_accuracy)\n",
        "\n",
        "# Make predictions on test data\n",
        "test_predictions = model.predict(test_preprocessed_images)\n",
        "# Decode the model's output to obtain predicted labels\n",
        "predicted_labels = lb.inverse_transform(test_predictions)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Convert encoded_test_labels to multiclass format\n",
        "test_labels = np.argmax(encoded_test_labels, axis=1)\n",
        "\n",
        "# Convert test_predictions to multiclass format\n",
        "predicted_classes = np.argmax(test_predictions, axis=1)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(test_labels, predicted_classes)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate precision, recall, and F1-score for each class\n",
        "precision = precision_score(test_labels, predicted_classes, average=None, zero_division=1)\n",
        "recall = recall_score(test_labels, predicted_classes, average=None)\n",
        "f1 = f1_score(test_labels, predicted_classes, average=None)\n",
        "\n",
        "# Print classification report\n",
        "for i, class_label in enumerate(class_labels):\n",
        "    print(\"Class:\", class_label)\n",
        "    print(\"Precision:\", precision[i])\n",
        "    print(\"Recall:\", recall[i])\n",
        "    print(\"F1-score:\", f1[i])\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXpuPM5EZzkS",
        "outputId": "a36f1bee-a6f9-4179-9751-5846e190e0a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step - loss: 0.4725 - accuracy: 0.5000\n",
            "Validation Loss: 0.47248631715774536\n",
            "Validation Accuracy: 0.5\n",
            "1/1 [==============================] - 0s 428ms/step\n",
            "Accuracy: 0.5\n",
            "Class: Abrasione\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n",
            "\n",
            "Class: Ammaccatura\n",
            "Precision: 1.0\n",
            "Recall: 0.0\n",
            "F1-score: 0.0\n",
            "\n",
            "Class: Crepa\n",
            "Precision: 0.3333333333333333\n",
            "Recall: 1.0\n",
            "F1-score: 0.5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 6: Model Comparison**\n",
        "\n"
      ],
      "metadata": {
        "id": "mBxAHQj09o6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create an empty dataframe\n",
        "df = pd.DataFrame(columns=['Model', 'Validation Loss', 'Validation Accuracy', 'Accuracy', 'Precision', 'Recall', 'F1-score'])\n",
        "\n",
        "# Model VGG16\n",
        "model1_name = 'Model VGG16'\n",
        "model1_val_loss = val_loss_VGG\n",
        "model1_val_accuracy = val_accuracy_VGG\n",
        "model1_accuracy = accuracy_VGG\n",
        "model1_precision = precision_VGG\n",
        "model1_recall = recall_VGG\n",
        "model1_f1 = f1_VGG\n",
        "\n",
        "# Add Model VGG16 results to the dataframe\n",
        "df = df.append({'Model': model1_name,\n",
        "                'Validation Loss': model1_val_loss,\n",
        "                'Validation Accuracy': model1_val_accuracy,\n",
        "                'Accuracy': model1_accuracy,\n",
        "                'Precision': model1_precision,\n",
        "                'Recall': model1_recall,\n",
        "                'F1-score': model1_f1}, ignore_index=True)\n",
        "\n",
        "# Model LeNet\n",
        "model2_name = 'Model LeNet'\n",
        "model2_val_loss = val_loss_LeNet\n",
        "model2_val_accuracy = val_accuracy_LeNet\n",
        "model2_accuracy = accuracy_LeNet\n",
        "model2_precision = precision_LeNet\n",
        "model2_recall = recall_LeNet\n",
        "model2_f1 = f1_LeNet\n",
        "\n",
        "# Add Model LeNet results to the dataframe\n",
        "df = df.append({'Model': model2_name,\n",
        "                'Validation Loss': model2_val_loss,\n",
        "                'Validation Accuracy': model2_val_accuracy,\n",
        "                'Accuracy': model2_accuracy,\n",
        "                'Precision': model2_precision,\n",
        "                'Recall': model2_recall,\n",
        "                'F1-score': model2_f1}, ignore_index=True)\n",
        "\n",
        "# Model Custom CNN\n",
        "model3_name = 'Custom CNN'\n",
        "model3_val_loss = val_loss\n",
        "model3_val_accuracy = val_accuracy\n",
        "model3_accuracy = accuracy\n",
        "model3_precision = precision\n",
        "model3_recall = recall\n",
        "model3_f1 = f1\n",
        "\n",
        "# Add Model Custom CNN results to the dataframe\n",
        "df = df.append({'Model': model3_name,\n",
        "                'Validation Loss': model3_val_loss,\n",
        "                'Validation Accuracy': model3_val_accuracy,\n",
        "                'Accuracy': model3_accuracy,\n",
        "                'Precision': model3_precision,\n",
        "                'Recall': model3_recall,\n",
        "                'F1-score': model3_f1}, ignore_index=True)\n",
        "\n",
        "# Display the dataframe\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v--F0gAI9lR6",
        "outputId": "9b0e57f7-d42b-4541-8470-3dc62cec3751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Model  Validation Loss  Validation Accuracy  Accuracy  \\\n",
            "0  Model VGG16        49.077660                  0.5       0.5   \n",
            "1  Model LeNet        38.678387                  0.5       0.5   \n",
            "2   Custom CNN         0.472486                  0.5       0.5   \n",
            "\n",
            "                        Precision           Recall         F1-score  \n",
            "0  [1.0, 1.0, 0.3333333333333333]  [1.0, 0.0, 1.0]  [1.0, 0.0, 0.5]  \n",
            "1  [1.0, 1.0, 0.3333333333333333]  [1.0, 0.0, 1.0]  [1.0, 0.0, 0.5]  \n",
            "2  [1.0, 1.0, 0.3333333333333333]  [1.0, 0.0, 1.0]  [1.0, 0.0, 0.5]  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-7ec73c80a09a>:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'Model': model1_name,\n",
            "<ipython-input-14-7ec73c80a09a>:34: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'Model': model2_name,\n",
            "<ipython-input-14-7ec73c80a09a>:52: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append({'Model': model3_name,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Results**\n",
        "\n",
        "Given the dataset is too small, with a test set of less than 5 images. It is clear that the custom CNN architecture I defined has performed best, the reason it is because I had to experiment with a lot of different configurations and number of layers, and it has performed best on the training metrics. but since the test set is very very small, percision, recall and f1 scores are the same. However, after adding image augmentation, the results have even improved drastically.\n",
        "\n"
      ],
      "metadata": {
        "id": "O3Rt6w7b9lo2"
      }
    }
  ]
}